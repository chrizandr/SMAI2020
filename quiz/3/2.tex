\begin{frame}
\section{}
Consider a single layer perceptron with two input and one output. The weights from from first and second inputs are $w_1$ and $w_2$ respectively. Also assume a -1, +1 logic. Let $w_0$ be the weights associated with bias $+1$.



The activation at the output is:
\[ \phi(x) = +1 \mbox{ if } x\geq 0  \mbox{ and } -1 \mbox{ else }\]


If $w_0 = 0, w_1 = 1, w_2 = 1 $, then this perceptron is equivalent to:

(fill from the gates like: AND, OR, ExOR, NAND, NOR)

% FIB

\end{frame}


\begin{frame}
\section{}
Consider a single layer perceptron with two input and one output. The weights from from first and second inputs are $w_1$ and $w_2$ respectively. Also assume a -1, +1 logic. Let $w_0$ be the weights associated with bias $+1$.



The activation at the output is:
\[ \phi(x) = +1 \mbox{ if } x\geq 0  \mbox{ and } -1 \mbox{ else }\]


If $w_0 = -1, w_1 = 1, w_2 = 1 $, then this perceptron is equivalent to:

(fill from the gates like: AND, OR, ExOR, NAND, NOR)

% FIB


\end{frame}


\begin{frame}
\section{}
Consider a single layer perceptron with two input and one output. The weights from from first and second inputs are $w_1$ and $w_2$ respectively. Also assume a -1, +1 logic. Let $w_0$ be the weights associated with bias $+1$.



The activation at the output is:
\[ \phi(x) = +1 \mbox{ if } x\geq 0  \mbox{ and } -1 \mbox{ else }\]


If $w_0 = 1, w_1 = -1, w_2 = -1 $, then this perceptron is equivalent to:

(fill from the gates like: AND, OR, ExOR, NAND, NOR)

% FIB


\end{frame}


\begin{frame}
\section{}
Consider a single layer perceptron with two input and one output. The weights from from first and second inputs are $w_1$ and $w_2$ respectively. Also assume a -1, +1 logic. Let $w_0$ be the weights associated with bias $+1$.



The activation at the output is:
\[ \phi(x) = +1 \mbox{ if } x\geq 0  \mbox{ and } -1 \mbox{ else }\]


If $w_0 = -1, w_1 = -1, w_2 = -1 $, then this perceptron is equivalent to:

(fill from the gates like: AND, OR, ExOR, NAND, NOR)

% FIB
\end{frame}
