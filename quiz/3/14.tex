
\begin{frame}
\section{}
Consider an MLP which is getting trained with Back Propagation for a multiclass classification problem.
\begin{enumerate}[label=(\Alph*)]
\item The performance of the final model will depend on the initialization.   % Ans
\item The performance of the final model will depend on the learning rate we use.   % Ans
\item The performance of the final model will depend on the termination criteria we use.    % Ans
\item The performance of the final model will depend on the loss function we use.   % Ans
\item Exactly three of the above four are correct.  % None

\end{enumerate}

\end{frame}


\begin{frame}
\section{}
Consider an MLP which is getting trained with Back Propagation for a multiclass classification problem.

\begin{enumerate}[label=(\Alph*)]
\item The optimization problem we solve is convex if the number of classes is  two.
\item The optimization problem we solve is non-convex independent of the number of classes.   % Ans
\item We typically terminate the training when we reach a local minima (ie., GD can not change the solution)    % Ans
\item When we stop the training with an ``early stopping criteria'', the solution is often not a local minima.
\item None of the above.    % None
\end{enumerate}
\end{frame}
