
\begin{frame}
\section{}
Consider a two class classification problem in 2 dimensions. We know that both the classes can be modelled as multivariate Gaussians. We have 1000 samples each from both the classes (i.e., N=2000).

If means are always well separated and variances are always small:

We use a linear SVM.
\begin{enumerate}[label=(\Alph*)]
\item number of support vectors will be very small (say closer to $d$ than closer to $N$)   % Ans
\item number of support vectors will be very larger (say closer to $N$ than closer to $d$).
\item in general, number of support vectors have nothing to do with the mean and variance of the classes.   % Ans
\item in general, number of support vectors depends on mean but not variance.
\item in general, number of support vectors depends on variance and not mean.
\end{enumerate}

\end{frame}


\begin{frame}
\section{}
Consider a two class classification problem in 2 dimensions. We know that both the classes can be modelled as multivariate Gaussians. We have 1000 samples each from both the classes (i.e., N=2000).

If means  are always equal and variances are  always equal for both the classes:

We use a linear SVM.

\begin{enumerate}[label=(\Alph*)]
\item number of support vectors will be very small (say closer to $d$ than closer to $N$)
\item number of support vectors will be very larger (say closer to $N$ than closer to $d$).    % Ans
\item in general, number of support vectors have nothing to do with the mean and variance of the classes.    % Ans
\item in general, number of support vectors depends on mean but not variance.
\item in general, number of support vectors depends on variance and not mean.
\end{enumerate}
\end{frame}


\begin{frame}
\section{}
Consider a two class classification problem in 2 dimensions. We know that both the classes can be modelled as multivariate Gaussians. We have 1000 samples each from both the classes (i.e., N=2000).

Bayesian Optimal Classifier gives 90\% as the optimal accuracy.

We use a linear SVM.

\begin{enumerate}[label=(\Alph*)]
\item number of Support Vectors will be closer to 0.9 N.
\item number of Support Vectors will be closer to 0.9 d.
\item number of Support Vectors will be closer to 0.1 N.    % Ans
\item number of Support Vectors will be closer to 0.1 d.
\item Bayesian optimal rate has no influence on the number of Support Vectors.
\end{enumerate}
\end{frame}
