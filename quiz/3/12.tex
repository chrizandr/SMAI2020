\begin{frame}
\section{}
For Kernel Percepron
\begin{enumerate}[label=(\Alph*)]
\item It can be used for linearly separable or non-separable data   % Ans
\item At test time, we evaluate it as: \[ sign ({\bf w}^T{\bf x})\]
\item At the test time, we evaluate it as: \[ sign (\sum_{i=1}^N \alpha_i y_i \kappa({\bf x}_i, {\bf x}) \]
\item At the test time, we evaluate it as: \[ sign (\sum_{i=1}^N \alpha_i \kappa({\bf x}_i, {\bf x}) \]   % Ans
\item when kernel is linear kernel, Kernel Perceptron reduces to the regular Perceptron.    % Ans
\end{enumerate}

\end{frame}



\begin{frame}
\section{}
Consider a set of $N$ valid kernels $\kappa_i(\cdot,\cdot)$

\begin{enumerate}[label=(\Alph*)]
\item $\sum_{i=1}^N \kappa_i()$  is also a valid kernel.    % Ans
\item $\sum_{i=1}^N \alpha_i \kappa_i()$  is also a valid kernel for any $\alpha_i \in R$.
\item $\sum_{i=1}^N \alpha_i \kappa_i()$  is also a valid kernel for any $\alpha_i \in R^+$.    % Ans
\item $\Pi_{i=1}^N \kappa_i()$  is also a valid kernel.   % Ans
\item All the above.    % None
\end{enumerate}
\end{frame}
